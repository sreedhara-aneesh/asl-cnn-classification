# Convolutional Neural Networks for ASL Image Classification

## Abstract

We develop a classifier to identify sign language symbols present in an image input with the use of a Convolutional Neural Network (CNN). Images depicting symbols within the American Sign Language (ASL) are used to train, validate, and test various convolutional neural networks with varying layer depths and activation functions to verify the impact of such variations on model performance.

## Report

See [`./report.pdf`](./report.pdf).

## Code

Code referenced in the report is provided in the following `.ipynb` files and was run on Google CoLab.
- [`var_convolutional_layers.ipynb`](./var_convolutional_layers.ipynb): models with varied convolutional layers
- [`var_dense_layers.ipynb`](./var_dense_layers.ipynb): models with varied dense layers
- [`var_pooling_type.ipynb`](./var_pooling_type.ipynb): models with varied pooling type

More information on our methods and approach are available in the aforementioned report.

Created models are present in the `models` folder.
